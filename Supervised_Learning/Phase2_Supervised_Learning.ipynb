{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0355a85",
   "metadata": {},
   "source": [
    "\n",
    "# Phase 2 — Supervised Learning (StudentsPerformance.csv)\n",
    "\n",
    "This notebook fulfills the **Phase 2** requirements:\n",
    "- Choose ≥2 supervised models with justification  \n",
    "- Implement training (with clean preprocessing)  \n",
    "- Evaluate & compare (Accuracy, Precision, Recall, F1, + optional CV)  \n",
    "- Interpret results and explain which model performed best and why  \n",
    "\n",
    "> Place this file in your repo under: `/Supervised_Learning/Phase2_Supervised_Learning.ipynb`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3945e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 0) Imports & basic setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0626f6fe",
   "metadata": {},
   "source": [
    "## 1) Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d562656",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make sure StudentsPerformance.csv is in the same folder as this notebook\n",
    "df = pd.read_csv(\"StudentsPerformance.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fec765",
   "metadata": {},
   "source": [
    "## 2) Create target label (Pass/Fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7880175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "score_cols = [\"math score\", \"reading score\", \"writing score\"]\n",
    "assert set(score_cols).issubset(df.columns), \"Score columns not found in CSV.\"\n",
    "\n",
    "df[\"average\"] = df[score_cols].mean(axis=1)\n",
    "df[\"performance\"] = (df[\"average\"] >= 60).astype(int)  # 1=Pass, 0=Fail\n",
    "\n",
    "df[score_cols + [\"average\",\"performance\"]].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0054e9ce",
   "metadata": {},
   "source": [
    "## 3) Features/Target split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1520afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = df[\"performance\"].copy()\n",
    "X = df.drop(columns=[\"performance\", \"average\"])\n",
    "\n",
    "num_cols = [c for c in X.columns if X[c].dtype != \"O\"]\n",
    "cat_cols = [c for c in X.columns if X[c].dtype == \"O\"]\n",
    "\n",
    "num_cols, cat_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ebed13",
   "metadata": {},
   "source": [
    "## 4) Preprocessing (ColumnTransformer + Pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debfa822",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_transformer = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_cols),\n",
    "        (\"cat\", categorical_transformer, cat_cols)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "preprocessor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6f196a",
   "metadata": {},
   "source": [
    "## 5) Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba8f169",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train.shape, X_test.shape, y_train.value_counts(normalize=True), y_test.value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5458761",
   "metadata": {},
   "source": [
    "## 6) Models: SVM (RBF) + Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568a5bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svm_clf = Pipeline(steps=[\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"clf\", SVC(kernel=\"rbf\", probability=False, random_state=42))\n",
    "])\n",
    "\n",
    "dt_clf = Pipeline(steps=[\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"clf\", DecisionTreeClassifier(max_depth=None, random_state=42))\n",
    "])\n",
    "\n",
    "models = {\n",
    "    \"SVM (RBF)\": svm_clf,\n",
    "    \"DecisionTree\": dt_clf\n",
    "}\n",
    "list(models.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308e90f2",
   "metadata": {},
   "source": [
    "## 7) Train & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136c7d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = []\n",
    "\n",
    "for name, pipe in models.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"Accuracy :\", round(acc, 4))\n",
    "    print(\"Precision:\", round(prec, 4))\n",
    "    print(\"Recall   :\", round(rec, 4))\n",
    "    print(\"F1-score :\", round(f1, 4))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    results.append((name, acc, prec, rec, f1))\n",
    "\n",
    "comp_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"]).sort_values(\"F1\", ascending=False)\n",
    "comp_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48c5ac4",
   "metadata": {},
   "source": [
    "## 8) Optional: 5-Fold Cross-Validation (F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9738f755",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv_summary = {}\n",
    "for name, pipe in models.items():\n",
    "    cv_scores = cross_val_score(pipe, X, y, cv=5, scoring=\"f1\")\n",
    "    cv_summary[name] = {\"mean\": cv_scores.mean(), \"std\": cv_scores.std()}\n",
    "pd.DataFrame(cv_summary).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d65516",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Results Interpretation (write here)\n",
    "- **Which model performed best?** Explain using F1 and other metrics.\n",
    "- **Why might it be better?** (e.g., non-linear boundaries in SVM, over/underfitting in DT).\n",
    "- **What features likely matter?** (Consider `test preparation course`, `lunch`, etc.)\n",
    "- **Any limitations?** (dataset size, class balance, need for hyperparameter tuning).\n",
    "\n",
    "> If you have time, add a grid search cell to tune SVM (C, gamma) and Decision Tree (max_depth, min_samples_split).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27c9aed",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Algorithm Selection & Justification (write here)\n",
    "- **SVM (RBF):** captures non-linear relationships; robust on medium-sized tabular data when features are scaled and categoricals are one-hot encoded.\n",
    "- **Decision Tree:** simple and interpretable baseline; shows if simple rules can separate classes; fast to train and understand.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741c7f42",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### ✅ Phase 2 Checklist\n",
    "- [ ] Two supervised models with clear justification  \n",
    "- [ ] Clean preprocessing via ColumnTransformer + Pipelines  \n",
    "- [ ] Train/Test split (and optional cross-validation)  \n",
    "- [ ] Metrics: Accuracy, Precision, Recall, F1 + Confusion Matrix  \n",
    "- [ ] A short interpretation explaining which model is best and why  \n",
    "- [ ] Save this notebook under `/Supervised_Learning/Phase2_Supervised_Learning.ipynb` in your GitHub repo  \n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
